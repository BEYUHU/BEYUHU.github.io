<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="/favicon/favicon.ico">
    <!--Description-->
    
        <meta name="description" content="BEIYUHU&#39;S STUDY ROOM">
    

    <!--Author-->
    
        <meta name="author" content="BEIYU HU">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="TASK04 - P13+P14"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content=""/>

    <!--Page Cover-->
    
        <meta property="og:image" content=""/>
    

    <!-- Title -->
    
    <title>TASK04 - P13+P14 - </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/sass/main.css">


    <!--[if lt IE 8]>
        
<script src="/js/ie/html5shiv.js"></script>

    <![endif]-->

    <!--[if lt IE 8]>
        
<link rel="stylesheet" href="/sass/ie8.css">

    <![endif]-->

    <!--[if lt IE 9]>
        
<link rel="stylesheet" href="/sass/ie9.css">

    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    


<meta name="generator" content="Hexo 5.4.0"></head>

<body>

    <div id="wrapper">

        <!-- Menu -->
        <!-- Header -->
<header id="header">
    <div class="inner">

        <!-- Logo -->
        <a href="/" class="logo">
            <span class="symbol"><img src="/images/BEYUHU.png" alt="" /></span><span class="title"></span>
        </a>

        <!-- Nav -->
        <nav>
            <ul>
                <li><a href="#menu">M E N U</a></li>
            </ul>
        </nav>

    </div>
</header>

<!-- Menu -->
<nav id="menu">
    <h2>M E N U</h2>
    <ul>
        
            <li>
                <a href="/">H O M E</a>
            </li>
        
            <li>
                <a href="/archives">A R C H I V E S</a>
            </li>
        
            <li>
                <a href="/CV.pdf">C V</a>
            </li>
        
            <li>
                <a target="_blank" rel="noopener" href="https://linkedin.com/in/beiyuhu">L i n k e d I n</a>
            </li>
        
    </ul>
</nav>


        <div id="main">
            <div class="inner">

                <!-- Main Content -->
                

    <h1>TASK04 - P13+P14</h1>


    <span class="image main"><img src="HUNGYILEE_04.png" alt="" /></span>


<!-- Gallery -->


<!-- Content -->
<h1 id="P13-Deep-Learning"><a href="#P13-Deep-Learning" class="headerlink" title="P13 Deep Learning"></a>P13 Deep Learning</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=13">Hung-yi Lee - Machine Learning 2017 - P13 深度学习</a></p>
<hr>
<h2 id="THREE-STEPS-FOR-DEEP-LEARNING"><a href="#THREE-STEPS-FOR-DEEP-LEARNING" class="headerlink" title="THREE STEPS FOR DEEP LEARNING"></a>THREE STEPS FOR DEEP LEARNING</h2><table>
<thead>
<tr>
<th>Step 1</th>
<th>Step 2</th>
<th>Step 3</th>
</tr>
</thead>
<tbody><tr>
<td>Define a function set</td>
<td>Goodness of function</td>
<td>Pick the best function</td>
</tr>
</tbody></table>
<h3 id="Step-1-Define-function"><a href="#Step-1-Define-function" class="headerlink" title="Step 1 : Define function"></a>Step 1 : Define function</h3><ul>
<li>这个function也就是神经网络Neural Network。</li>
</ul>
<h4 id="1-1-Neural-Network-是什么？"><a href="#1-1-Neural-Network-是什么？" class="headerlink" title="1.1 Neural Network 是什么？"></a>1.1 Neural Network 是什么？</h4><p>由不同的logistic regression连接（concatenate）在一起，把其中一个logistic regression称之为神经元Neuron。</p>
<h4 id="1-2-神经元-Neuron-中："><a href="#1-2-神经元-Neuron-中：" class="headerlink" title="1.2 神经元 Neuron 中："></a>1.2 神经元 Neuron 中：</h4><ol>
<li>Network <strong>structures</strong>: 不同的连接。不同于regression不需考虑structure，神经网络中的structure(有多少层layer，每层layer有多少neuron等)很重要</li>
<li>Network <strong>parameter</strong> <em>θ</em>: 大堆logistic regression的weight和bias集合起来</li>
</ol>
<h4 id="1-3-neuron间怎么连接？"><a href="#1-3-neuron间怎么连接？" class="headerlink" title="1.3 neuron间怎么连接？"></a>1.3 neuron间怎么连接？</h4><ol>
<li>最常见的称作：Fully Connect Feedforward Network<ol>
<li>把神经元排成一排一排</li>
<li>每个neuron都有一组weight和bias，通过training data找出来</li>
</ol>
</li>
<li>整个process：<br>  <code>input</code> → <code>matrix运算</code> (diff. weight &amp; bias) → <code>logistic regression(sigmoid function)</code> → 重复于不同layer → <code>output</code><br>  input是一个vector，output也会是一个vector<br> 给定的结构 = define a function set</li>
</ol>
<h4 id="1-4-Fully-Connect-Feedforward-Network"><a href="#1-4-Fully-Connect-Feedforward-Network" class="headerlink" title="1.4 Fully Connect Feedforward Network"></a>1.4 Fully Connect Feedforward Network</h4><ol>
<li>layer和layer之间两两相连，所以称之为fully connect</li>
<li>从layer1传到layer2，由后往前传（此处 <strong>后</strong>指layer数字更小，即<u>远离output端</u>为<strong>后</strong>，靠近<u>output端</u>为<strong>前</strong>）</li>
<li><code>Input Layer</code> → <code>Hidden Layers</code> → <code>Output Layer</code><br> 那Deep Learning中的 Deep = Many <code>Hidden Layers</code>。</li>
</ol>
<h4 id="1-5-Network的运作：Martix-Operation"><a href="#1-5-Network的运作：Martix-Operation" class="headerlink" title="1.5 Network的运作：Martix Operation"></a>1.5 Network的运作：Martix Operation</h4><p align="center"><img src="operation.png" width="50%"><br><img src="operation2.png" width="50%"></p>

<ol>
<li>blue: <code>input</code> = vector</li>
<li>yellow: <code>weight</code> = matrix</li>
<li>green: <code>bias</code> = vector</li>
<li>blue: <code>output</code> = logistic regression, 可以是sigmoid, 但现在并不常用 </li>
</ol>
<h4 id="1-6-Output-layer"><a href="#1-6-Output-layer" class="headerlink" title="1.6 Output layer"></a>1.6 Output layer</h4><ol>
<li>Output Layer之前的部分看作是特征值提取器（feature extractor），代替特征工程（feature engineering）</li>
<li>Output Layer为多级分离器（multi-class classifier）<br> 相当于前面<code>Hidden Layers</code> 中抽出一组特别好的feature，并用multi-class classifier分类好，用softmax function。</li>
</ol>
<h4 id="1-7-Structure"><a href="#1-7-Structure" class="headerlink" title="1.7 Structure"></a>1.7 Structure</h4><ol>
<li>多少层？多少神经元？<br> 多尝试+直觉（经验）</li>
<li>结构自动生成：Evolutionary Artificial Neural Networks</li>
<li>自己设计结构：CNN Convolutional Neural Network</li>
</ol>
<h3 id="Step-2-Goodness-of-function"><a href="#Step-2-Goodness-of-function" class="headerlink" title="Step 2 : Goodness of function"></a>Step 2 : Goodness of function</h3><p>output为y，target为y^，目标就是y,y^ 越小越好。</p>
<p>Total Loss: L = Σ C<sup>n</sup>(θ) 即所有loss的总损失最少。<br>→ gradient descent → network parameter θ调整</p>
<ul>
<li>Backpropagation：反向传播有效计算w对L的微分<br>  有以下toolkit：<p align="center"><img src="bp.png" width="80%"></p></li>
</ul>
<h3 id="Step-3-Pick-the-best-function"><a href="#Step-3-Pick-the-best-function" class="headerlink" title="Step 3 : Pick the best function"></a>Step 3 : Pick the best function</h3><hr>
<h1 id="P14-Backpropagation"><a href="#P14-Backpropagation" class="headerlink" title="P14 Backpropagation"></a>P14 Backpropagation</h1><p> by  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=14">Hung-yi Lee - Machine Learning 2017 - P14 反向传播</a></p>
<h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><p> 通过微分或偏微分的分裂，把初始函数和目标函数对应。</p>
<ul>
<li>Case 1. 串联： <em>y = g(x), z = h(y)</em><br> Δ<em>x</em> →  Δ<em>y</em> → Δ<em>z</em> </li>
<li>Case 2. 串联： <em>x = g(s), y=h(s), z = k(x,y)</em><br>  Δ<em>s</em> →  Δ<em>x</em> → Δ<em>z</em><br>  Δ<em>s</em> → Δ<em>y</em> → Δ<em>z</em>  </li>
</ul>
<h3 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h3><ol>
<li><p>求Loss function L(θ) = ΣC<sup>n</sup>(θ) 对w的偏导：<br>𝜕L(θ)/𝜕w = Σ 𝜕C<sup>n</sup>(θ)/𝜕w</p>
</li>
<li><p>展开后：<br>𝜕C/𝜕w = (𝜕z/𝜕w) * (𝜕C/𝜕z)<br>其中前项：<code>𝜕z/𝜕w</code> = x (input项)，因为z = x<sub>1</sub>w<sub>1</sub>+x<sub>2</sub>w<sub>2</sub>+…+b<br>也就是可以用Forward path正向计算偏微分。</p>
</li>
<li><p>但是：展开式后项 <code>𝜕C/𝜕z</code> 很难算，所以用Backward path来算。其过程相当于电路中放大器的做法。</p>
</li>
<li><p>backward path的需要正向算完，得出output后，再反向算得偏导。</p>
</li>
</ol>


<!-- Tags -->



<div class="tags">
    <a href="/tags/MachineLearning/" class="button small">MachineLearning</a> <a href="/tags/Hung-yi-Lee/" class="button small">Hung-yi_Lee</a>
</div>



<!-- Comments -->
<div>
    
    <hr />
    <h3>Comments:</h3>
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>



</div>



            </div>
        </div>

        <!-- Footer -->
<footer id="footer">
    <div class="inner">
        <section>
            <div>
                A little blog for note sharing, check the  <b><a href="/about" target="_self"> info</a></b> about everything! :)
            </div>
        </section>
        <section>
            
            </ul>
        </section>
        <ul class="copyright">
            <li>&copy; BH. All rights reserved</li>
        </ul>
    </div>
</footer>
    </div>

    <!-- After footer scripts -->
    
<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- skel -->

<script src="/js/skel.min.js"></script>


<!-- Custom Code -->

<script src="/js/util.js"></script>


<!--[if lte IE 8]>

<script src="/js/ie/respond.min.js"></script>

<![endif]-->

<!-- Custom Code -->

<script src="/js/main.js"></script>


<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->

<script type="text/javascript">
    var disqus_shortname = 'GUESTS';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>


</body>

</html>