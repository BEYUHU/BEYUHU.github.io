<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="/favicon/favicon.ico">
    <!--Description-->
    
        <meta name="description" content="BEIYUHU&#39;S STUDY ROOM">
    

    <!--Author-->
    
        <meta name="author" content="BEIYU HU">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Kazmi - Energy prediction"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content=""/>

    <!--Page Cover-->
    
        <meta property="og:image" content=""/>
    

    <!-- Title -->
    
    <title>Kazmi - Energy prediction - </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/sass/main.css">


    <!--[if lt IE 8]>
        
<script src="/js/ie/html5shiv.js"></script>

    <![endif]-->

    <!--[if lt IE 8]>
        
<link rel="stylesheet" href="/sass/ie8.css">

    <![endif]-->

    <!--[if lt IE 9]>
        
<link rel="stylesheet" href="/sass/ie9.css">

    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    


<meta name="generator" content="Hexo 5.4.0"></head>

<body>

    <div id="wrapper">

        <!-- Menu -->
        <!-- Header -->
<header id="header">
    <div class="inner">

        <!-- Logo -->
        <a href="/" class="logo">
            <span class="symbol"><img src="/images/BEYUHU.png" alt="" /></span><span class="title"></span>
        </a>

        <!-- Nav -->
        <nav>
            <ul>
                <li><a href="#menu">M E N U</a></li>
            </ul>
        </nav>

    </div>
</header>

<!-- Menu -->
<nav id="menu">
    <h2>M E N U</h2>
    <ul>
        
            <li>
                <a href="/">H O M E</a>
            </li>
        
            <li>
                <a href="/archives">C O L L E C T I O N</a>
            </li>
        
            <li>
                <a href="/CV.pdf">C V</a>
            </li>
        
            <li>
                <a target="_blank" rel="noopener" href="https://linkedin.com/in/beiyuhu">L i n k e d I n</a>
            </li>
        
    </ul>
</nav>


        <div id="main">
            <div class="inner">

                <!-- Main Content -->
                

    <h1>Kazmi - Energy prediction</h1>



<!-- Gallery -->


<!-- Content -->
<p><em>This note showed only my personal solution to some of the exercises asked in the JupyterNotebook from the lecture 2 and 3 following the open-source course <a target="_blank" rel="noopener" href="https://github.com/hussainkazmi/energyDS">energyDS</a> by <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/hussain-kazmi/">Hussain Kazmi</a>, please refer to his GitHub page for further study. The lecture and also prerequisites of Python have been WELL EXPLAINED everything related to energy prediction using python and data-driven approaches.</em></p>
<hr>
<p id="index"></p>

<table>
<thead>
<tr>
<th align="left">INDEX</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><a href="#01">LECTURE 2 Exercises: Fitting by <code>.polyfit()</code></a></td>
</tr>
<tr>
<td align="left"><a href="#02">LECTURE 3 Exercises 1: AUTOCORRELATION</a></td>
</tr>
<tr>
<td align="left"><a href="#03">LECTURE 3 Exercises 2: error metrics</a></td>
</tr>
<tr>
<td align="left"><a href="#04">LECTURE 3 Exercises 3: Linear regression fitting</a></td>
</tr>
</tbody></table>
<p id="01" align="right"><a href="#index">[ B A C K ]</a></p>
<p align="center"> </p>


<h2 id="LECTURE-2-Exercises-Fitting-by-polyfit"><a href="#LECTURE-2-Exercises-Fitting-by-polyfit" class="headerlink" title="LECTURE 2 Exercises: Fitting by .polyfit()"></a>LECTURE 2 Exercises: Fitting by <code>.polyfit()</code></h2><ol>
<li><p>Fit a line (linear function) to the three plots we have created in this section using <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html">this library</a></p>
</li>
<li><p>Fit higher order functions (2 to 20) to the datasets using the same library (by changing the polynomial degree in the arguments). Explain what happens as you increase the order of the polynomial. Pay particular attention to regions where you have few data points and when you are extrapolating (i.e. predicting beyond what was observed).</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#solution to Q1</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = [<span class="number">15</span>, <span class="number">15</span>]</span><br><span class="line">plt.rcParams.update(&#123;<span class="string">&#x27;font.size&#x27;</span>: <span class="number">12</span>&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">x1=np.arange(<span class="number">100</span>) <span class="comment"># x range</span></span><br><span class="line">deg1=<span class="number">1</span></span><br><span class="line">y1=np.poly1d(np.polyfit(linear_signal1,linear_signal2,deg1))</span><br><span class="line">plt.scatter(linear_signal1, linear_signal2,alpha=<span class="number">.2</span>,label=<span class="string">&#x27;Linear&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.plot(x1,y1(x1),<span class="string">&#x27;--&#x27;</span>,alpha=<span class="number">.5</span>,label=<span class="string">&#x27;Linear fit&#x27;</span>+<span class="built_in">str</span>(y1),color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(label=<span class="string">&#x27;Linear Scatter Fitting [deg=&#x27;</span>+<span class="built_in">str</span>(deg1)+<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">x2=np.arange(<span class="number">100</span>) <span class="comment"># x range</span></span><br><span class="line">deg2=<span class="number">3</span></span><br><span class="line">y2=np.poly1d(np.polyfit(noise_signal1,noise_signal2,deg2))</span><br><span class="line">plt.scatter(noise_signal1, noise_signal2,alpha=<span class="number">.2</span>,label=<span class="string">&#x27;Noise&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(x2,y2(x2),<span class="string">&#x27;--&#x27;</span>,alpha=<span class="number">.5</span>,label=<span class="string">&#x27;Noise fit&#x27;</span>+<span class="built_in">str</span>(y2),color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(label=<span class="string">&#x27;Noise Scatter Fitting [deg=&#x27;</span>+<span class="built_in">str</span>(deg2)+<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">3</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">x3=np.arange(-<span class="number">10</span>,<span class="number">10</span>) <span class="comment"># x range</span></span><br><span class="line">deg3=<span class="number">2</span></span><br><span class="line">y3=np.poly1d(np.polyfit(nonLinear_signal1,nonLinear_signal2,deg3))</span><br><span class="line">plt.scatter(nonLinear_signal1, nonLinear_signal2,alpha=<span class="number">.2</span>,label=<span class="string">&#x27;Non-linear&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.plot(x3,y3(x3),<span class="string">&#x27;--&#x27;</span>,alpha=<span class="number">.5</span>,label=<span class="string">&#x27;Non-linear fit&#x27;</span>+<span class="built_in">str</span>(y3),color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(label=<span class="string">&#x27;Non-linear Scatter Fitting [deg=&#x27;</span>+<span class="built_in">str</span>(deg3)+<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p align='center'><img src='output_82_0.png' width='100%'></p>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># comments to Q2: </span></span><br><span class="line"><span class="comment"># It will be closer to some of the scatters, but it could be overfitting, </span></span><br><span class="line"><span class="comment"># which means that if there are some test dataset, the performance would be worse.</span></span><br></pre></td></tr></table></figure>
<p id="02" align="right"><a href="#index">[ B A C K ]</a></p>
<p align="center"> </p>

<h2 id="LECTURE-3-Exercises-1-AUTOCORRELATION"><a href="#LECTURE-3-Exercises-1-AUTOCORRELATION" class="headerlink" title="LECTURE 3 Exercises 1: AUTOCORRELATION"></a>LECTURE 3 Exercises 1: AUTOCORRELATION</h2><ol>
<li>Load the three datasets with missing values from lecture 2. Now create a time series which contains a value of 1 at the indices where the time series has a missing value (and takes a value of 0 elsewhere). Repeat this for all three time series with missing values. Now calculate the autocorrelation function for these new time series. What do you notice in the autocorrelation functions?</li>
<li>Decompose the time series into its components, as discussed earlier. What conclusions can you draw?</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step 1 : missing data visualization</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> missingno <span class="keyword">as</span> msno</span><br><span class="line"></span><br><span class="line">demand= pd.read_csv(<span class="string">&#x27;LoadData.csv&#x27;</span>, header=<span class="literal">None</span>, usecols=[<span class="number">0</span>])[<span class="number">0</span>:<span class="number">672</span>]</span><br><span class="line">demand[<span class="string">&#x27;missing1&#x27;</span>] = pickle.load(<span class="built_in">open</span>(<span class="string">&quot;LoadData_missing1.p&quot;</span>, <span class="string">&quot;rb&quot;</span>))</span><br><span class="line">demand[<span class="string">&#x27;missing2&#x27;</span>] = pickle.load(<span class="built_in">open</span>(<span class="string">&quot;LoadData_missing2.p&quot;</span>, <span class="string">&quot;rb&quot;</span>))</span><br><span class="line">demand[<span class="string">&#x27;missing3&#x27;</span>] = pickle.load(<span class="built_in">open</span>(<span class="string">&quot;LoadData_missing3.p&quot;</span>, <span class="string">&quot;rb&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2 : sustitute NaN to 1 and the rest to 0</span></span><br><span class="line"></span><br><span class="line">df1=pd.DataFrame(demand[<span class="string">&#x27;missing1&#x27;</span>])</span><br><span class="line">missing1=df1.isna().replace(&#123;<span class="literal">True</span>: <span class="number">1</span>,<span class="literal">False</span>: <span class="number">0</span>&#125;)</span><br><span class="line">        </span><br><span class="line">df2=pd.DataFrame(demand[<span class="string">&#x27;missing2&#x27;</span>])</span><br><span class="line">missing2=df2.isna().replace(&#123;<span class="literal">True</span>: <span class="number">1</span>,<span class="literal">False</span>: <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line">df3=pd.DataFrame(demand[<span class="string">&#x27;missing3&#x27;</span>])</span><br><span class="line">missing3=df3.isna().replace(&#123;<span class="literal">True</span>: <span class="number">1</span>,<span class="literal">False</span>: <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># or use the following:</span></span><br><span class="line"><span class="comment"># df1=pd.Dataframe(demand[&#x27;missing1&#x27;])</span></span><br><span class="line"><span class="comment"># missing1=df1.copy</span></span><br><span class="line"><span class="comment"># nalis=df1.isna</span></span><br><span class="line"><span class="comment"># missing1[nalis] = 0</span></span><br><span class="line"><span class="comment"># missing1[~nalis] =1</span></span><br><span class="line"></span><br><span class="line">msno.matrix(demand)</span><br><span class="line">plt.show()</span><br><span class="line">plt.scatter(np.arange(<span class="built_in">len</span>(missing1)),missing1,alpha=<span class="number">.5</span>)</span><br><span class="line">plt.scatter(np.arange(<span class="built_in">len</span>(missing2)),missing2,alpha=<span class="number">.5</span>)</span><br><span class="line">plt.scatter(np.arange(<span class="built_in">len</span>(missing3)),missing3,alpha=<span class="number">.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p align='center'><img src='output_106_0.png' width='100%'></p>
<p align='center'><img src='output_106_1.png' width='100%'></p>
 



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step 3: Autocorrelation and decomposition of new time series </span></span><br><span class="line"></span><br><span class="line">sm.graphics.tsa.plot_acf(missing1, lags=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">result = STL(missing1[<span class="number">0</span>:-<span class="number">1</span>], period=<span class="number">100</span>).fit()</span><br><span class="line">result.plot()</span><br><span class="line"></span><br><span class="line">sm.graphics.tsa.plot_acf(missing2, lags=<span class="number">100</span>)</span><br><span class="line">result = STL(missing2[<span class="number">0</span>:-<span class="number">1</span>], period=<span class="number">100</span>).fit()</span><br><span class="line">result.plot()</span><br><span class="line"></span><br><span class="line">sm.graphics.tsa.plot_acf(missing3, lags=<span class="number">100</span>)</span><br><span class="line">result = STL(missing3[<span class="number">0</span>:-<span class="number">1</span>], period=<span class="number">100</span>).fit()</span><br><span class="line">result.plot()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="missing-1"><a href="#missing-1" class="headerlink" title="missing 1"></a>missing 1</h3><p align='center'><img src='output_107_0.png' width='100%'></p>
<p align='center'><img src='output_107_1.png' width='100%'></p>

<h3 id="missing-2"><a href="#missing-2" class="headerlink" title="missing 2"></a>missing 2</h3><p align='center'><img src='output_107_2.png' width='100%'></p>    
<p align='center'><img src='output_107_3.png' width='100%'></p>    

<h3 id="missing-3"><a href="#missing-3" class="headerlink" title="missing 3"></a>missing 3</h3><p align='center'><img src='output_107_4.png' width='100%'></p>
<p align='center'><img src='output_107_5.png' width='100%'></p>    




<p id="03" align="right"><a href="#index">[ B A C K ]</a></p>
<p align="center"> </p>

<h2 id="LECTURE-3-Exercises-2-error-metrics"><a href="#LECTURE-3-Exercises-2-error-metrics" class="headerlink" title="LECTURE 3 Exercises 2: error metrics"></a>LECTURE 3 Exercises 2: error metrics</h2><ol>
<li>In this section, we have made a forecast for just one day. In practice, this forecast needs to be created every day (and sometimes updated multiple times during each day as well). For instance, demand aggregators need to make a forecast for electricity demand everyday so they can participate in electricity markets. Rewrite the code above to create a one-day ahead persistence forecast for the whole year, storing the daily forecast for each day in a vector. Using this forecast, calculate the MAE and MAPE of this forecast, and the coefficient of determination.</li>
<li>Calculate the autocorrelation of the error time series (i.e. measured values - forecast values) calculated for the whole year. What do you infer from the results?</li>
<li>What insights do you draw based on the type of error the persistence forecast is making? Note that information in the following section on visualizing errors will also be useful to answering this question.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># solution to Q1:</span></span><br><span class="line"></span><br><span class="line">predict = np.array(electricity[<span class="number">0</span>:-<span class="number">96</span>])</span><br><span class="line">actual = np.array(electricity[<span class="number">96</span>:])</span><br><span class="line">plt.plot(predict, label=<span class="string">&#x27;Predict&#x27;</span>,alpha=<span class="number">.5</span>)</span><br><span class="line">plt.plot(actual, label=<span class="string">&#x27;Actual&#x27;</span>,alpha=<span class="number">.5</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time [15-min intervals]&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Power [kW]&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.scatter(actual, predict, alpha=<span class="number">0.05</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">200</span>), <span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Measured time series&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Predicted time series&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line">mae=mean_absolute_error(actual,predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MAE = &#x27;</span>+<span class="built_in">str</span>(<span class="built_in">round</span>(mae,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_absolute_percentage_error</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>((y_true - y_pred) / y_true)) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">mape=mean_absolute_percentage_error(actual, predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MAPE = &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(mape,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2=r2_score(actual, predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;R2 = &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(r2,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p align='center'><img src='output_118_0.png' width='100%'></p>
<p align='center'><img src='output_118_1.png' width='100%'></p>    

<pre><code>MAE = 9.22
MAPE = 10.76
R2 = 0.79
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># solution to Q2:</span></span><br><span class="line"></span><br><span class="line">error_time_series = actual-predict</span><br><span class="line"></span><br><span class="line">plt.hist(error_time_series)</span><br><span class="line">plt.title(label=<span class="string">&#x27;Histogram&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">60</span>,<span class="number">60</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plot_ACF(np.correlate(error_time_series,error_time_series, mode=<span class="string">&#x27;full&#x27;</span>))</span><br><span class="line">sm.graphics.tsa.plot_acf(error_time_series, lags=<span class="number">50</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">result = STL(error_time_series[<span class="number">0</span>:-<span class="number">1</span>], period=<span class="number">50</span>).fit()</span><br><span class="line">result.plot()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p align='center'><img src='output_119_0.png' width='100%'></p>
<p align='center'><img src='output_119_1.png' width='100%'></p>    
<p align='center'><img src='output_119_2.png' width='100%'></p>
<p align='center'><img src='output_119_3.png' width='100%'></p>
    


<h4 id="Visualizing-errors"><a href="#Visualizing-errors" class="headerlink" title="Visualizing errors"></a>Visualizing errors</h4><p>NOTE: The following contents are mainly written by prof Kazmi, but when I run the code and it is not showing what I expected. Therefore, I changed some of them as following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create 2D chart of the errors</span></span><br><span class="line"></span><br><span class="line">sampleFreq = <span class="number">96</span></span><br><span class="line">days=<span class="built_in">int</span>(error_time_series.shape[<span class="number">0</span>]/sampleFreq)</span><br><span class="line"></span><br><span class="line"><span class="comment"># original one did not assign sampleFreq and days, </span></span><br><span class="line"><span class="comment"># also with (days-1) as x-axis which it is already done for the previous steps</span></span><br><span class="line"></span><br><span class="line">error2D = error_time_series.reshape(days, sampleFreq)</span><br><span class="line"></span><br><span class="line">plt.imshow(error2D, cmap=<span class="string">&#x27;magma&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Time of day [15-min intervals]&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Day of year&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p align='center'><img src='output_122_0.png' width='40%'></p>
 

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># boxplot</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plb</span><br><span class="line"></span><br><span class="line">plb.boxplot(error2D)</span><br><span class="line">plb.xlabel(<span class="string">&#x27;Time of day [15-min intervals]&#x27;</span>)</span><br><span class="line">plb.ylabel(<span class="string">&#x27;Prediction error [kW]&#x27;</span>)</span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">120</span>, <span class="number">20</span>) </span><br><span class="line"><span class="comment"># original code is (0, 100, 20) which would have errors in the x.ticks</span></span><br><span class="line"></span><br><span class="line">labels = [<span class="number">0</span>,<span class="number">20</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">80</span>,<span class="number">100</span>]</span><br><span class="line">plb.xticks(x)</span><br><span class="line">plb.xticks(x,labels)</span><br><span class="line">plb.grid(<span class="literal">True</span>)</span><br><span class="line">plb.show()</span><br></pre></td></tr></table></figure>


<p align='center'><img src='output_126_0.png' width='100%'></p>


<p id="04" align="right"><a href="#index">[ B A C K ]</a></p>
<p align="center"> </p>    


<h3 id="Training-a-linear-model"><a href="#Training-a-linear-model" class="headerlink" title="Training a linear model"></a>Training a linear model</h3><p>NOTE: The code below was written by the author prof Kazmi, the reason to keep it is that it would related to the later exercises.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span>(<span class="params">load, currentIndex, featureCounter</span>):</span></span><br><span class="line">    xVar[featureCounter, :] = load[currentIndex - <span class="number">96</span>*<span class="number">7</span> : currentIndex]</span><br><span class="line">    yVar[featureCounter] = load[currentIndex]</span><br><span class="line">    <span class="keyword">return</span> xVar, yVar</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">lin_model = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line">xVar = np.zeros((number_days * sampling_frequency, <span class="number">7</span> * <span class="number">96</span>))</span><br><span class="line">yVar = np.zeros(number_days * sampling_frequency)</span><br><span class="line"></span><br><span class="line">feature_counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span> * sampling_frequency, <span class="number">28</span> * sampling_frequency):</span><br><span class="line">    <span class="comment"># Update feature vector for training</span></span><br><span class="line">    xVar, yVar = extract_features(electricity, i, feature_counter)</span><br><span class="line">    feature_counter = feature_counter + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(feature_counter)</span><br></pre></td></tr></table></figure>

<pre><code>2016
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lin_model.fit(xVar[<span class="number">0</span>:feature_counter, :], yVar[<span class="number">0</span>:feature_counter])</span><br></pre></td></tr></table></figure>


<pre><code>LinearRegression()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">prediction_linear = lin_model.predict(xVar[<span class="number">0</span>:feature_counter, :])</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = [<span class="number">15</span>, <span class="number">10</span>]</span><br><span class="line">plt.rcParams.update(&#123;<span class="string">&#x27;font.size&#x27;</span>: <span class="number">15</span>&#125;)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(lin_model.coef_)</span><br><span class="line">plt.title(label=<span class="string">&#x27;Coefficients of the linear model&#x27;</span>)</span><br><span class="line">plt.ylim(-<span class="number">0.1</span>,<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot(prediction_linear)</span><br><span class="line">plt.title(label=<span class="string">&#x27;Prediction&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p align='center'><img src='output_146_0.png' width='100%'></p>


<h2 id="LECTURE-3-Exercises-3-Linear-regression-fitting"><a href="#LECTURE-3-Exercises-3-Linear-regression-fitting" class="headerlink" title="LECTURE 3 Exercises 3: Linear regression fitting"></a>LECTURE 3 Exercises 3: Linear regression fitting</h2><ol>
<li><p>Create day-ahead forecasts for the whole year with the linear model (as you did previously for the persistence model). Assume that each day at midnight, you must create a forecast for the next 96 quarters. Compare the two methods (persistence and the linear model). Does the MAPE and R2 values of a linear model improve or worsen when compared with persistence? How does the rMAE look like? Is it greater than or smaller than 1?</p>
</li>
<li><p>Where we load the data, we aggregate demand for all houses and therefore make an aggregated forecast. Increasingly, with peer to peer concepts, it is becoming important to forecast energy demand in individual households. Rerun your code with data from a single household.</p>
</li>
<li><p>Estimate how the training time of your models scales as you increase the amount of training data. </p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">feature_counter_year = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span> * sampling_frequency, <span class="number">350</span> * sampling_frequency):</span><br><span class="line">    <span class="comment"># Update feature vector for training</span></span><br><span class="line">    xVar, yVar = extract_features(electricity, i, feature_counter_year)</span><br><span class="line">    feature_counter_year = feature_counter_year + <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Prediction time:&#x27;</span>+<span class="built_in">str</span>(feature_counter_year))</span><br><span class="line"></span><br><span class="line">start=datetime.datetime.now()</span><br><span class="line">year=lin_model.fit(xVar[<span class="number">0</span>:feature_counter_year, :], yVar[<span class="number">0</span>:feature_counter_year])</span><br><span class="line">pred=lin_model.predict(xVar[<span class="number">0</span>:feature_counter_year, :])</span><br><span class="line">act=yVar[<span class="number">0</span>:feature_counter_year]</span><br><span class="line">end=datetime.datetime.now()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;time = &#x27;</span>+<span class="built_in">str</span>(end-start))</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>]=[<span class="number">20</span>,<span class="number">5</span>]</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(np.arange(feature_counter_year),act,label=<span class="string">&#x27;Actual&#x27;</span>,alpha=<span class="number">.5</span>,s=<span class="number">1</span>)</span><br><span class="line">plt.scatter(np.arange(feature_counter_year),pred,label=<span class="string">&#x27;Predict&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>,alpha=<span class="number">.5</span>,s=<span class="number">1</span>)</span><br><span class="line">plt.xlim(<span class="number">0</span>,feature_counter_year)</span><br><span class="line">plt.title(label=<span class="string">&#x27;Time series&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.scatter(act,pred,alpha=<span class="number">.2</span>,s=<span class="number">.2</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Prediction&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Actual&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="number">200</span>),<span class="string">&#x27;--&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">mape_linear=mean_absolute_percentage_error(act, pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MAPE = &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(mape_linear,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2_linear=r2_score(act, pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;R2 = &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(r2_linear,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> mape &gt; mape_linear:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;MAPE: Persistence &gt; Linear Regression |&#x27;</span>+<span class="string">&#x27; MAPE difference = &#x27;</span>+<span class="built_in">str</span>(<span class="built_in">round</span>(<span class="built_in">abs</span>(mape-mape_linear),<span class="number">2</span>)))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;MAPE: Persistence &lt; Linear Regression |&#x27;</span>+<span class="string">&#x27; MAPE difference = &#x27;</span>+<span class="built_in">str</span>(<span class="built_in">round</span>(<span class="built_in">abs</span>(mape-mape_linear),<span class="number">2</span>)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;rMAE = &#x27;</span>+<span class="built_in">str</span>(<span class="built_in">round</span>(mape_linear/mape,<span class="number">2</span>)))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> r2 &gt; r2_linear:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;R2: Persistence &gt; Linear Regression |&#x27;</span>+<span class="string">&#x27; R2 difference = &#x27;</span>+<span class="built_in">str</span>(<span class="built_in">round</span>(<span class="built_in">abs</span>(r2-r2_linear),<span class="number">2</span>)))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;R2: Persistence &lt; Linear Regression |&#x27;</span>+<span class="string">&#x27; R2 difference = &#x27;</span>+<span class="built_in">str</span>(<span class="built_in">round</span>(<span class="built_in">abs</span>(r2-r2_linear),<span class="number">2</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>Prediction time:32928
time = 0:00:00.895473
</code></pre>
<p align='center'><img src='output_151_1.png' width='100%'></p>

<pre><code>rMAE = 0.46
MAPE = 4.97
R2 = 0.96

MAPE: 
Persistence &gt; Linear Regression | MAPE difference = 5.79

R2: 
Persistence &lt; Linear Regression | R2 difference = 0.17
</code></pre>
<p><em>that means linear regression is better than the persistance model</em></p>


<!-- Tags -->



<div class="tags">
    <a href="/tags/Energy/" class="button small">Energy</a> <a href="/tags/Hussain-Kazmi/" class="button small">Hussain_Kazmi</a>
</div>



<!-- Comments -->
<div>
    
    <hr />
    <h3>Comments:</h3>
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>



</div>



            </div>
        </div>

        <!-- Footer -->
<footer id="footer">
    <div class="inner">
        <section>
            <div>
                A little blog for note sharing, check the  <b><a href="/about" target="_self"> info</a></b> about everything! :)
            </div>
        </section>
        <section>
            
            </ul>
        </section>
        <ul class="copyright">
            <li>&copy; BH. All rights reserved</li>
        </ul>
    </div>
</footer>
    </div>

    <!-- After footer scripts -->
    
<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- skel -->

<script src="/js/skel.min.js"></script>


<!-- Custom Code -->

<script src="/js/util.js"></script>


<!--[if lte IE 8]>

<script src="/js/ie/respond.min.js"></script>

<![endif]-->

<!-- Custom Code -->

<script src="/js/main.js"></script>


<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->

<script type="text/javascript">
    var disqus_shortname = 'GUESTS';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>


</body>

</html>